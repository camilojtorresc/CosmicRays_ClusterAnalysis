{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2580b4f4",
   "metadata": {},
   "source": [
    "**Original author:  Camilo J. Torres             \n",
    "created:  march of 2024\n",
    "          personal email: <camilojtorresc@gmail.com>\n",
    "          email:  <camilo.torres@cern.ch>**\n",
    "\n",
    "Version 8 updates:\n",
    "- Implement a form to convert the ROOT5 files provided by CORSIKA into a Pandas data frame to analize the simulations with the method implemented in previous versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5a9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cc1961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: uproot3 in /home/user/.local/lib/python3.10/site-packages (3.14.4)\n",
      "Requirement already satisfied: awkward0 in /home/user/.local/lib/python3.10/site-packages (from uproot3) (0.15.5)\n",
      "Requirement already satisfied: uproot3-methods in /home/user/.local/lib/python3.10/site-packages (from uproot3) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /home/user/.local/lib/python3.10/site-packages (from uproot3) (1.24.2)\n",
      "Requirement already satisfied: cachetools in /usr/lib/python3/dist-packages (from uproot3) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "# install and import uproot\n",
    "!pip install uproot3\n",
    "import uproot3 as uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8277c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the file with the data of particles\n",
    "path = r'/home/user/Documents/BUAP/Estancia/CosmicRayReco/MCAnalysis/ClusterAnalysis/Data'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2a723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with ROOT5 format\n",
    "root_data = 'DataUSC/DAT000004.root'\n",
    "\n",
    "# Open the sim tree\n",
    "simulation = uproot.open(root_data)['sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca2f2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'shower.', b'particle.', b'long.', b'cherenkov.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the Branches in the 'sim' tree\n",
    "simulation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2182853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'shower.TObject',\n",
       " b'shower.fParticles',\n",
       " b'shower.fCherenkov',\n",
       " b'shower.EventID',\n",
       " b'shower.Energy',\n",
       " b'shower.StartingAltitude',\n",
       " b'shower.FirstTarget',\n",
       " b'shower.FirstHeight',\n",
       " b'shower.Theta',\n",
       " b'shower.Phi',\n",
       " b'shower.RandomSeed[10]',\n",
       " b'shower.RandomOffset[10]',\n",
       " b'shower.nPhotons',\n",
       " b'shower.nElectrons',\n",
       " b'shower.nHadrons',\n",
       " b'shower.nMuons',\n",
       " b'shower.nParticlesWritten',\n",
       " b'shower.nPhotonsWritten',\n",
       " b'shower.nElectronsWritten',\n",
       " b'shower.nHadronsWritten',\n",
       " b'shower.nMuonsWritten',\n",
       " b'shower.GH_Nmax',\n",
       " b'shower.GH_t0',\n",
       " b'shower.GH_tmax',\n",
       " b'shower.GH_a',\n",
       " b'shower.GH_b',\n",
       " b'shower.GH_c',\n",
       " b'shower.GH_Chi2',\n",
       " b'shower.nPreshower',\n",
       " b'shower.CPUtime']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation[\"shower.\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a55066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NShow</th>\n",
       "      <th>Energy</th>\n",
       "      <th>ZFInt</th>\n",
       "      <th>ZhAng</th>\n",
       "      <th>AzAng</th>\n",
       "      <th>NParticles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.579618</td>\n",
       "      <td>15.897397</td>\n",
       "      <td>30.570698</td>\n",
       "      <td>-104.965866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>7.955384</td>\n",
       "      <td>10.797235</td>\n",
       "      <td>33.753933</td>\n",
       "      <td>165.915329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>10.202897</td>\n",
       "      <td>15.586424</td>\n",
       "      <td>11.866905</td>\n",
       "      <td>17.410604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>11.754333</td>\n",
       "      <td>13.532733</td>\n",
       "      <td>27.440584</td>\n",
       "      <td>-60.561756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>8.494957</td>\n",
       "      <td>24.328083</td>\n",
       "      <td>7.733621</td>\n",
       "      <td>36.078545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>99979</td>\n",
       "      <td>8.870023</td>\n",
       "      <td>23.504463</td>\n",
       "      <td>11.639350</td>\n",
       "      <td>-99.643448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>99980</td>\n",
       "      <td>10.474447</td>\n",
       "      <td>14.565544</td>\n",
       "      <td>12.646334</td>\n",
       "      <td>-18.351109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>99989</td>\n",
       "      <td>8.313620</td>\n",
       "      <td>11.972643</td>\n",
       "      <td>26.025732</td>\n",
       "      <td>106.134659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>99995</td>\n",
       "      <td>11.782672</td>\n",
       "      <td>16.127588</td>\n",
       "      <td>12.844821</td>\n",
       "      <td>44.257046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99996</td>\n",
       "      <td>10.048354</td>\n",
       "      <td>22.197723</td>\n",
       "      <td>23.737793</td>\n",
       "      <td>-157.630508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9537 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NShow     Energy      ZFInt      ZhAng       AzAng  NParticles\n",
       "entry                                                                \n",
       "4          5   7.579618  15.897397  30.570698 -104.965866           1\n",
       "9         10   7.955384  10.797235  33.753933  165.915329           1\n",
       "13        14  10.202897  15.586424  11.866905   17.410604           2\n",
       "22        23  11.754333  13.532733  27.440584  -60.561756           1\n",
       "44        45   8.494957  24.328083   7.733621   36.078545           1\n",
       "...      ...        ...        ...        ...         ...         ...\n",
       "99978  99979   8.870023  23.504463  11.639350  -99.643448           1\n",
       "99979  99980  10.474447  14.565544  12.646334  -18.351109           2\n",
       "99988  99989   8.313620  11.972643  26.025732  106.134659           1\n",
       "99994  99995  11.782672  16.127588  12.844821   44.257046           1\n",
       "99995  99996  10.048354  22.197723  23.737793 -157.630508           1\n",
       "\n",
       "[9537 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowerVar = ['shower.EventID','shower.Energy','shower.FirstHeight',\n",
    "             'shower.Theta','shower.Phi','shower.nParticlesWritten'] # Choose the interest variables\n",
    "\n",
    "Showers = simulation.arrays(ShowerVar, outputtype=pd.DataFrame) # Transform into pdf\n",
    "Showers = Showers[Showers['shower.nParticlesWritten']!=0] # Ignore showers without particles in measurement height\n",
    "\n",
    "# Redefine the variables in the pdf\n",
    "Showers['shower.FirstHeight'] = Showers['shower.FirstHeight']/1e5\n",
    "Showers['shower.Theta'] = Showers['shower.Theta']*180/np.pi\n",
    "Showers['shower.Phi'] = Showers['shower.Phi']*180/np.pi\n",
    "\n",
    "# Rename columns\n",
    "Showers = Showers.rename(columns={ShowerVar[0]: 'NShow', ShowerVar[1]: 'Energy',\n",
    "                                  ShowerVar[2]: 'ZFInt', ShowerVar[3]: 'ZhAng',\n",
    "                                  ShowerVar[4]: 'AzAng', ShowerVar[5]: 'NParticles'})\n",
    "\n",
    "Showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation[\"particle.\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a bit more complex for particles to extract into a Pandas data frame\n",
    "\n",
    "ParticleVar = ['shower.EventID','shower.nParticlesWritten','particle..ParticleID',\n",
    "               'particle..x','particle..y','particle..Time',\n",
    "              'particle..Px','particle..Py','particle..Pz'] # Interest variables\n",
    "\n",
    "particle_df = simulation.arrays(ParticleVar, outputtype=pd.DataFrame) # Extract the variables from branch\n",
    "particle_df = particle_df[particle_df[\"shower.nParticlesWritten\"]!=0] # Ignore showers without particles in measurement height\n",
    "\n",
    "partnum = particle_df.size # Number of particles \n",
    "\n",
    "particle_df = particle_df.to_dict() # Transform into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e391b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Particles = {\"NShow\": [], \"PId\": [], \"X\": [], \"Y\": [], \"T\": [],\n",
    "            \"Px\":[], \"Py\": [], \"Pz\": []} # Create the new data frma\n",
    "Particles = pd.DataFrame(Particles) \n",
    "\n",
    "ShowerNum = Showers['NShow'].tolist() # List with all the shower id with particles at measurement height\n",
    "\n",
    "for i in range(len(ShowerNum)):\n",
    "    part_sh = particle_df['particle..ParticleID'][ShowerNum[i]-1].size # Number of particles in the shower\n",
    "    \n",
    "    for j in range(part_sh): # Fill the Particles pdf with the info of the dictionary \n",
    "        list_for_df = [ShowerNum[i],\n",
    "                      particle_df['particle..ParticleID'][ShowerNum[i]-1][j],\n",
    "                      particle_df['particle..x'][ShowerNum[i]-1][j],\n",
    "                      particle_df['particle..y'][ShowerNum[i]-1][j],\n",
    "                      particle_df['particle..Time'][ShowerNum[i]-1][j],\n",
    "                      particle_df['particle..Px'][ShowerNum[i]-1][j],\n",
    "                      particle_df['particle..Py'][ShowerNum[i]-1][j],\n",
    "                      particle_df['particle..Pz'][ShowerNum[i]-1][j]\n",
    "                      ]\n",
    "\n",
    "        Particles.loc[i+1] = list_for_df # Fill new row\n",
    "        \n",
    "# Redefine the variables in the pdf\n",
    "Particles[\"X\"] = Particles[\"X\"]/1e2\n",
    "Particles[\"Y\"] = Particles[\"Y\"]/1e2\n",
    "Particles[\"PSq\"] = Particles[\"Px\"]**2+Particles[\"Py\"]**2+Particles[\"Pz\"]**2\n",
    "Particles[\"Ene\"] = np.sqrt(Particles[\"PSq\"])\n",
    "Particles[\"ZhA\"] = np.arctan2(np.sqrt((Particles[\"Py\"])**2+(Particles[\"Px\"])**2),Particles[\"Pz\"])*(180.0/np.pi)\n",
    "Particles[\"AzA\"] = np.arctan2(Particles[\"Py\"],Particles[\"Px\"])*(180.0/np.pi)\n",
    "\n",
    "Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File with summary of Showers\n",
    "#Showers = pd.read_csv(r'DAT000006_1k_showers.txt',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File with information of all particles at observation level\n",
    "#Particles = pd.read_csv('DAT000006_1k_particles.txt',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e6050-053d-4b29-b6cf-a6f77b74d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run summary\n",
    "Energies = {'E1': 9, 'E2': 11, 'E3': 14, 'E4': 18, 'E5': 55, 'E6':70}\n",
    "Run = {'SCod': 'Corsika-77500','Mass':[1],'Lab': ['BUAP'], 'NShows':[100000], 'EInf': [7] , 'ESup': [13], 'AAInf':[0], 'AASup':[37]} \n",
    "Run = pd.DataFrame(Run)\n",
    "\n",
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00fd29-9136-4fe1-814c-ee64b6ce9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "Showers['Mass'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics of the data frame with summary of showers \n",
    "Showers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43fa31-7bc5-4cc1-9e67-8b26cc9a72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local particles codes for labeling clusters\n",
    "# Particle Corsika PID       P. Code\n",
    "# Gamma        1              1\n",
    "# Electrons    2,3            1000\n",
    "# Muons        5,6            100000\n",
    "# Pions        8,9            50000000\n",
    "# Protons      14             10000000\n",
    "# Neutrons     13             100000000\n",
    "nop   = -999.\n",
    "gam   = 1.\n",
    "ele   = 1000.\n",
    "mu    = 100000.\n",
    "pi    = 50000000.\n",
    "prn   = 10000000.\n",
    "ntn   = 100000000. \n",
    "\n",
    "pmap   = {1.:gam,2.:ele,3.:ele,5.:mu,6.:mu,8.:pi, 9.:pi, 13.:ntn, 14.:prn}\n",
    "#pmap   = {'1.':'gam','2.':'ele','3.':'ele','5.':'mu','6.':'mu','8.':'pi','9.':'pi', '13.':'ntn', '14.':'prn'}\n",
    "#pid    = [1., 2., 3., 5., 6., 8., 9., 13., 14.]\n",
    "#zipped = list(zip(pid,pcode))\n",
    "#pcode  = pd.DataFrame(zipped, columns=['pid', 'pcode'])\n",
    "Particles['R'] = np.sqrt(Particles['X']**2 + Particles['Y']**2)\n",
    "Particles['PCode'] = Particles['PId'].map(pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdb52a-e9be-4cc8-b265-ab1a61b97f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Particles.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observatory layout\n",
    "det_s_x = 1.0 # detector size in x axis (m)\n",
    "det_s_y = 1.0 # detector size in y axis (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ee2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The values in the 'DetMdx' and 'DetMdy' columns will be replaced by the rounded values \n",
    "#of the positions of the particles, this will define the position of the cell\n",
    "#\n",
    "Particles['DetX'] = np.floor(Particles['X']/det_s_x) + det_s_x/2\n",
    "Particles['DetY'] = np.floor(Particles['Y']/det_s_x) + det_s_y/2\n",
    "#\n",
    "Particles['PartX'] = 1000 * (Particles['X'] - Particles['DetX']) # mm\n",
    "Particles['PartY'] = 1000 * (Particles['Y'] - Particles['DetY']) # mm\n",
    "#Add a new column which will contain the number of cluster \n",
    "Particles['NClst'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c52cd-f72f-4f24-bbcb-e3ee5149dd12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Particles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f3268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Clusters(iclust, PartS, ClustDF):\n",
    "    # Find clusters of particles in a shower\n",
    "    # iclust: number of cluster\n",
    "    # Shower: number of shower\n",
    "    \n",
    "    XPos = PartS['DetX'].tolist()\n",
    "    YPos = PartS['DetY'].tolist()\n",
    "    \n",
    "    unique_pairs = set() # Create an empty set\n",
    "\n",
    "    # Iterate over the pairs of x and y using zip\n",
    "    for xi, yi in zip(XPos, YPos):\n",
    "        pair = (xi, yi)\n",
    "        \n",
    "        #VarClust = []\n",
    "\n",
    "        # Check if the pair is already in the set\n",
    "        if pair not in unique_pairs:\n",
    "            unique_pairs.add(pair) # If not, add it to the set\n",
    "\n",
    "            # Extract the particles index by comparing it with the x, y position in the data frame\n",
    "            p_index_clust = PartS.index[ (PartS['DetX'] == xi) & (PartS['DetY'] == yi) ].tolist()\n",
    "            \n",
    "            # Replacte the cluster position of the particle for the cluster id\n",
    "            for j in range(len(p_index_clust)):\n",
    "                PartS.at[p_index_clust[j],'NClst'] = iclust\n",
    "            \n",
    "            # For one particle clusters\n",
    "            if(len(p_index_clust) == 1):\n",
    "                \n",
    "                df_clust = PartS[PartS['NClst']==iclust]\n",
    "                \n",
    "                ClsIdC = df_clust[\"PCode\"].tolist()[0]\n",
    "                NpartC = df_clust.shape[0]\n",
    "                NGamC = df_clust[df_clust['PCode']==1.].shape[0]\n",
    "                NEleC = df_clust[df_clust['PCode']==1000.].shape[0]\n",
    "                NMuCl = df_clust[df_clust['PCode']==100000.].shape[0]\n",
    "                XmClst = df_clust[\"X\"].tolist()[0]\n",
    "                YmClst = df_clust[\"Y\"].tolist()[0]\n",
    "                RmClst = df_clust[\"R\"].tolist()[0]\n",
    "                SigRCl = 0\n",
    "                TmClst = df_clust[\"T\"].tolist()[0]\n",
    "                dTClst = df_clust[\"T\"].max()-df_clust[\"T\"].min()\n",
    "                sTClst = 0\n",
    "                FstPID = ClsIdC\n",
    "                FstPCX = df_clust[\"Px\"].tolist()[0]\n",
    "                FstPCY = df_clust[\"Py\"].tolist()[0]\n",
    "                FstPCT = df_clust[\"T\"].tolist()[0]\n",
    "                FstPZh = df_clust[\"ZhA\"].tolist()[0]\n",
    "                FstPAz = df_clust[\"AzA\"].tolist()[0]\n",
    "                FstPPm = np.sqrt(FstPCX**2+FstPCY**2+df_clust[\"Pz\"].tolist()[0]**2)\n",
    "                LstPID = FstPID\n",
    "                LstPCX = FstPCX\n",
    "                LstPCY = FstPCY\n",
    "                LstPCT = FstPCT\n",
    "                LstPZh = FstPZh\n",
    "                LstPAz = FstPAz\n",
    "                LstPPm = FstPPm\n",
    "            \n",
    "            # For clusters with more than 1 particle\n",
    "            if(len(p_index_clust) > 1):\n",
    "                # Calculate variables and fill the Cluster dataframe\n",
    "                df_clust = PartS[PartS['NClst']==iclust]\n",
    "                FirstPart = df_clust[df_clust['T'] == df_clust[\"T\"].min()]\n",
    "                LastPart = df_clust[df_clust['T'] == df_clust[\"T\"].max()]\n",
    "                \n",
    "                ClustStats_mean = df_clust[[\"X\",\"Y\",\"R\",\"T\"]].mean()\n",
    "                ClustStats_std  = df_clust[[\"X\",\"Y\",\"R\", \"T\"]].std()\n",
    "                \n",
    "                ClsIdC = df_clust[\"PCode\"].sum()\n",
    "                NpartC = df_clust.shape[0]\n",
    "                NGamC = df_clust[df_clust['PCode']==1.].shape[0]\n",
    "                NEleC = df_clust[df_clust['PCode']==1000.].shape[0]\n",
    "                NMuCl = df_clust[df_clust['PCode']==100000.].shape[0]\n",
    "                XmClst = ClustStats_mean[\"X\"]\n",
    "                YmClst = ClustStats_mean[\"Y\"]\n",
    "                RmClst = ClustStats_mean[\"R\"]\n",
    "                SigRCl = ClustStats_std[\"R\"]\n",
    "                TmClst = ClustStats_mean[\"T\"]\n",
    "                dTClst = df_clust[\"T\"].max()-df_clust[\"T\"].min()\n",
    "                sTClst = ClustStats_std[\"T\"]\n",
    "                FstPID = FirstPart[\"PCode\"].tolist()[0]\n",
    "                FstPCX = FirstPart[\"Px\"].tolist()[0]\n",
    "                FstPCY = FirstPart[\"Py\"].tolist()[0]\n",
    "                FstPCT = FirstPart[\"T\"].tolist()[0]\n",
    "                FstPZh = FirstPart[\"ZhA\"].tolist()[0]\n",
    "                FstPAz = FirstPart[\"AzA\"].tolist()[0]\n",
    "                FstPPm = np.sqrt(FirstPart[\"Px\"].tolist()[0]**2+FirstPart[\"Py\"].tolist()[0]**2+FirstPart[\"Pz\"].tolist()[0]**2)\n",
    "                LstPID = LastPart[\"PCode\"].tolist()[0]\n",
    "                LstPCX = LastPart[\"Px\"].tolist()[0]\n",
    "                LstPCY = LastPart[\"Py\"].tolist()[0]\n",
    "                LstPCT = LastPart[\"T\"].tolist()[0]\n",
    "                LstPZh = LastPart[\"ZhA\"].tolist()[0]\n",
    "                LstPAz = LastPart[\"AzA\"].tolist()[0]\n",
    "                LstPPm = np.sqrt(LastPart[\"Px\"].tolist()[0]**2+LastPart[\"Py\"].tolist()[0]**2+LastPart[\"Pz\"].tolist()[0]**2)\n",
    "                \n",
    "\n",
    "            VarClust = [iclust, ClsIdC, NpartC, NGamC, NEleC, NMuCl,\n",
    "                           XmClst, YmClst, RmClst, SigRCl,\n",
    "                           TmClst, dTClst, sTClst,\n",
    "                           FstPID, FstPCX, FstPCY, FstPCT, FstPZh, FstPAz, FstPPm,\n",
    "                           LstPID, LstPCX, LstPCY, LstPCT, LstPZh, LstPAz, LstPPm]\n",
    "                \n",
    "            ClustDF.loc[len(ClustDF.index)] = VarClust # Fill new row\n",
    "\n",
    "            \n",
    "            iclust = iclust+1 # Next Cluster\n",
    "    \n",
    "    return iclust, PartS, ClustDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484235fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the dataframe for cluster info.\n",
    "ClusterDF = {\"NClst\": [],'ClsIdC': [], 'NpartC': [], \"NGamC\": [], \"NEleC\": [],\"NMuCl\": [],\n",
    "            \"XmClst\": [], \"YmClst\": [], \"RmClst\": [], \"SigRCl\": [],\n",
    "            \"TmClst\": [], \"dTClst\": [], \"sTClst\": [],\n",
    "            \"FstPID\": [], \"FstPCX\": [], \"FstPCY\": [], \"FstPCT\": [], \"FstPZh\": [], \"FstPAz\": [], \"FstPPm\": [],\n",
    "            \"LstPID\": [], \"LstPCX\": [], \"LstPCY\": [], \"LstPCT\": [], \"LstPZh\": [], \"LstPAz\": [], \"LstPPm\": []\n",
    "            } \n",
    "\n",
    "ClusterDF = pd.DataFrame(ClusterDF)\n",
    "iclust = 1 # Cluster counter\n",
    "\n",
    "# Run over all the showers\n",
    "nsh = Showers['NShow'].tolist()\n",
    "for ishow in nsh:\n",
    "    Shower = Particles[Particles['NShow']==ishow]   #current shower\n",
    "    iclust, Nshow, ClusterDF = Clusters(iclust, Shower, ClusterDF) \n",
    "    Particles.loc[Particles['NShow']==ishow, :] = Nshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are particles that are not counted\n",
    "Particles[Particles[\"NClst\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b79def",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0407c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of the cluster with the maximum number of particles\n",
    "df_sn = Particles[Particles[\"NClst\"]!=0]\n",
    "Max_ClustId = df_sn[\"NClst\"].value_counts().idxmax()\n",
    "print(Max_ClustId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ecde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the cluster with the maximum number of particles\n",
    "Particles[Particles[\"NClst\"]==Max_ClustId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4abf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the cluster with the maximum number of particles\n",
    "ClusterDF[ClusterDF[\"NClst\"]==Max_ClustId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfdeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the cell with the maximum number of particles\n",
    "cx = Particles.loc[Particles[\"NClst\"]==Max_ClustId,'DetX'].iloc[0]\n",
    "cy = Particles.loc[Particles[\"NClst\"]==Max_ClustId,'DetY'].iloc[0]\n",
    "Mx = Particles.loc[Particles[\"NClst\"]==Max_ClustId,'PartX']\n",
    "My = Particles.loc[Particles[\"NClst\"]==Max_ClustId,'PartY']\n",
    "plt.scatter(Mx,My)\n",
    "plt.title('Cell: X=%i, Y=%i'%(cx,cy))\n",
    "plt.xlabel('X (mm)')\n",
    "plt.ylabel('Y (mm)')\n",
    "#Cell for detector of 1 m^2 \n",
    "plt.axis([-500,500,-500,500])\n",
    "#Cell for detector of 0.30 x 0.30 m^2\n",
    "#plt.axis([-150,150,-150,150])\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
